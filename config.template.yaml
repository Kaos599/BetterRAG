# BetterRAG Configuration Template
# Copy this file to config.yaml and fill in your own values

# General configuration
general:
  db_reset: false  # Set to true to clear the database before processing
  data_source: "./data/documents/"  # Directory containing documents to process
  output_directory: "./results/"  # Directory for evaluation results and charts
  test_queries_file: "./data/test_queries.json"  # File containing test queries
  parallel_evaluation: true  # Enable parallel processing for evaluation
  max_workers: 4  # Maximum number of worker threads for parallel processing
  batch_size: 10   # Number of queries to process in each batch
  enable_model_caching: true  # Enable caching of model calls
  enable_parameter_optimization: false  # Enable integrated parameter optimization with main workflow

# Model configuration
model:
  provider: "azure_openai"  # Options: "azure_openai", "gemini"
  
  # Azure OpenAI configuration (required if provider is "azure_openai")
  azure_openai:
    api_key: "${AZURE_OPENAI_API_KEY}"  # Environment variable or your actual API key
    api_base: "${AZURE_OPENAI_ENDPOINT}"  # Environment variable or your actual endpoint
    api_version: "2023-05-15"
    embedding_deployment: "text-embedding-ada-002"
    completion_deployment: "gpt-4"
    max_tokens: 1000
    temperature: 0.0
  
  # Google Gemini configuration (required if provider is "gemini")
  gemini:
    api_key: "${GOOGLE_API_KEY}"  # Environment variable or your actual API key
    embedding_model: "embedding-001"
    completion_model: "gemini-1.5-pro"
    max_tokens: 1000
    temperature: 0.0

# Database configuration
database:
  provider: "mongodb"
  mongodb:
    connection_string: "mongodb://localhost:27017/"  # Replace with your MongoDB connection string
    database_name: "betterrag"
    collection_name: "chunks"

# Chunking strategies to evaluate
chunking_strategies:
  fixed_size:
    enabled: true
    chunk_size: 500
    chunk_overlap: 50
  
  recursive:
    enabled: true
    chunk_size: 500
    chunk_overlap: 50
    separators: ["\n\n", "\n", ". ", " ", ""]
  
  semantic:
    enabled: true
    min_chunk_size: 100
    max_chunk_size: 600
    similarity_threshold: 0.7

# Parameter optimization settings
parameter_optimization:
  # These settings are used when parameter optimization is enabled
  
  # Chunk sizes to test
  chunk_sizes: [256, 512, 768, 1024]
  
  # Overlap percentages to test (as decimals)
  overlap_percentages: [0.12, 0.15, 0.18, 0.20, 0.25, 0.30]
  
  # Semantic methods to test
  semantic_methods: ["standard", "interquartile", "percentile"]
  
  # Similarity thresholds to test
  similarity_thresholds: [0.65, 0.75, 0.85, 0.95]
  
  # Whether to include the best parameters in the main dashboard
  include_in_main_dashboard: true

# Evaluation configuration
evaluation:
  top_k: 5  # Number of chunks to retrieve for each query
  metrics:
    - "context_precision"
    - "token_efficiency"
    - "retrieval_time"
    - "generation_time"
  weight:
    context_precision: 0.4
    token_efficiency: 0.3
    retrieval_time: 0.1
    generation_time: 0.1
    chunk_similarities: 0.1

# Visualization configuration
visualization:
  save_format: ["png", "html"]
  dashboard:
    port: 8050
    debug: false
    show_individual_chunks: true 